{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Music Genre Classification Project\n",
    "\n",
    "## Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv('data/train1.csv')\n",
    "labels = train_data['label']\n",
    "train_data = train_data.drop(['filename', 'label', 'length'], axis=1)\n",
    "\n",
    "# Encode the genre labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaryan Shetty\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## Build and Compile Models\n",
    "# Build the ANN model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')  # 10 output neurons for 10 genres\n",
    "])\n",
    "\n",
    "# Build the second ANN model\n",
    "model2 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation=lambda x: tf.keras.activations.relu(x, alpha=0.01)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')  # 10 output neurons for 10 genres\n",
    "])\n",
    "\n",
    "# Build the third ANN model\n",
    "model3 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')  # 10 output neurons for 10 genres\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3089 - loss: 1.9473 - val_accuracy: 0.5870 - val_loss: 1.1761\n",
      "Epoch 2/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5530 - loss: 1.2557 - val_accuracy: 0.6504 - val_loss: 0.9979\n",
      "Epoch 3/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6056 - loss: 1.1071 - val_accuracy: 0.6959 - val_loss: 0.8883\n",
      "Epoch 4/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6470 - loss: 1.0113 - val_accuracy: 0.7215 - val_loss: 0.8328\n",
      "Epoch 5/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6734 - loss: 0.9127 - val_accuracy: 0.7449 - val_loss: 0.7793\n",
      "Epoch 6/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6909 - loss: 0.8903 - val_accuracy: 0.7499 - val_loss: 0.7507\n",
      "Epoch 7/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7042 - loss: 0.8525 - val_accuracy: 0.7404 - val_loss: 0.7341\n",
      "Epoch 8/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.8252 - val_accuracy: 0.7665 - val_loss: 0.7176\n",
      "Epoch 9/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7224 - loss: 0.7883 - val_accuracy: 0.7732 - val_loss: 0.6854\n",
      "Epoch 10/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7423 - loss: 0.7481 - val_accuracy: 0.7754 - val_loss: 0.6588\n",
      "Epoch 11/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7483 - loss: 0.7315 - val_accuracy: 0.7954 - val_loss: 0.6352\n",
      "Epoch 12/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7564 - loss: 0.7052 - val_accuracy: 0.7921 - val_loss: 0.6286\n",
      "Epoch 13/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7621 - loss: 0.6852 - val_accuracy: 0.8027 - val_loss: 0.6027\n",
      "Epoch 14/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7734 - loss: 0.6453 - val_accuracy: 0.8088 - val_loss: 0.5777\n",
      "Epoch 15/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7739 - loss: 0.6557 - val_accuracy: 0.8082 - val_loss: 0.5844\n",
      "Epoch 16/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7776 - loss: 0.6306 - val_accuracy: 0.8088 - val_loss: 0.5675\n",
      "Epoch 17/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7895 - loss: 0.6216 - val_accuracy: 0.8143 - val_loss: 0.5513\n",
      "Epoch 18/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7871 - loss: 0.6198 - val_accuracy: 0.8221 - val_loss: 0.5550\n",
      "Epoch 19/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7939 - loss: 0.5946 - val_accuracy: 0.8227 - val_loss: 0.5375\n",
      "Epoch 20/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7919 - loss: 0.5928 - val_accuracy: 0.8199 - val_loss: 0.5333\n",
      "Epoch 21/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7966 - loss: 0.5930 - val_accuracy: 0.8316 - val_loss: 0.5347\n",
      "Epoch 22/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8053 - loss: 0.5522 - val_accuracy: 0.8344 - val_loss: 0.5129\n",
      "Epoch 23/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8012 - loss: 0.5540 - val_accuracy: 0.8360 - val_loss: 0.5129\n",
      "Epoch 24/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8003 - loss: 0.5581 - val_accuracy: 0.8332 - val_loss: 0.5160\n",
      "Epoch 25/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8020 - loss: 0.5535 - val_accuracy: 0.8466 - val_loss: 0.4999\n",
      "Epoch 26/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8144 - loss: 0.5313 - val_accuracy: 0.8399 - val_loss: 0.5040\n",
      "Epoch 27/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8212 - loss: 0.5204 - val_accuracy: 0.8432 - val_loss: 0.4980\n",
      "Epoch 28/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8273 - loss: 0.4908 - val_accuracy: 0.8449 - val_loss: 0.4909\n",
      "Epoch 29/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8301 - loss: 0.4923 - val_accuracy: 0.8438 - val_loss: 0.4873\n",
      "Epoch 30/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8225 - loss: 0.5028 - val_accuracy: 0.8438 - val_loss: 0.4740\n",
      "Epoch 31/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8202 - loss: 0.5039 - val_accuracy: 0.8427 - val_loss: 0.4838\n",
      "Epoch 32/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8136 - loss: 0.5299 - val_accuracy: 0.8460 - val_loss: 0.4690\n",
      "Epoch 33/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.4821 - val_accuracy: 0.8627 - val_loss: 0.4561\n",
      "Epoch 34/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8265 - loss: 0.4823 - val_accuracy: 0.8455 - val_loss: 0.4762\n",
      "Epoch 35/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8325 - loss: 0.4746 - val_accuracy: 0.8560 - val_loss: 0.4662\n",
      "Epoch 36/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8211 - loss: 0.4885 - val_accuracy: 0.8571 - val_loss: 0.4524\n",
      "Epoch 37/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4559 - val_accuracy: 0.8555 - val_loss: 0.4534\n",
      "Epoch 38/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.4586 - val_accuracy: 0.8605 - val_loss: 0.4467\n",
      "Epoch 39/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8477 - loss: 0.4467 - val_accuracy: 0.8621 - val_loss: 0.4460\n",
      "Epoch 40/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.4600 - val_accuracy: 0.8549 - val_loss: 0.4495\n",
      "Epoch 41/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4701 - val_accuracy: 0.8644 - val_loss: 0.4449\n",
      "Epoch 42/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4741 - val_accuracy: 0.8555 - val_loss: 0.4506\n",
      "Epoch 43/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.4589 - val_accuracy: 0.8594 - val_loss: 0.4429\n",
      "Epoch 44/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.4637 - val_accuracy: 0.8571 - val_loss: 0.4482\n",
      "Epoch 45/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8496 - loss: 0.4375 - val_accuracy: 0.8571 - val_loss: 0.4449\n",
      "Epoch 46/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.4261 - val_accuracy: 0.8599 - val_loss: 0.4289\n",
      "Epoch 47/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.4338 - val_accuracy: 0.8655 - val_loss: 0.4349\n",
      "Epoch 48/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8589 - loss: 0.4042 - val_accuracy: 0.8710 - val_loss: 0.4323\n",
      "Epoch 49/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8638 - loss: 0.3948 - val_accuracy: 0.8621 - val_loss: 0.4370\n",
      "Epoch 50/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8555 - loss: 0.4255 - val_accuracy: 0.8560 - val_loss: 0.4391\n",
      "Epoch 51/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8553 - loss: 0.4192 - val_accuracy: 0.8638 - val_loss: 0.4381\n",
      "Epoch 52/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8589 - loss: 0.3938 - val_accuracy: 0.8716 - val_loss: 0.4331\n",
      "Epoch 53/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8527 - loss: 0.4109 - val_accuracy: 0.8722 - val_loss: 0.4229\n",
      "Epoch 54/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8538 - loss: 0.4096 - val_accuracy: 0.8733 - val_loss: 0.4266\n",
      "Epoch 55/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8596 - loss: 0.4040 - val_accuracy: 0.8694 - val_loss: 0.4276\n",
      "Epoch 56/56\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8628 - loss: 0.3902 - val_accuracy: 0.8749 - val_loss: 0.4113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x228267a8e90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the Model\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=56, batch_size=20, validation_data=(X_valid, y_valid))\n",
    "# model.fit(X_train, y_train, epochs=39, batch_size=64, validation_data=(X_valid, y_valid))\n",
    "# model.fit(X_train, y_train, epochs=60, batch_size=32, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8717 - loss: 0.3863\n",
      "Validation Accuracy: 0.8749305009841919\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the Model\n",
    "# Evaluate the model\n",
    "validation_loss, validation_accuracy = model.evaluate(X_valid, y_valid)\n",
    "print(f'Validation Accuracy: {validation_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "## Predict and Save Results\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('data/test1.csv')\n",
    "\n",
    "# Extract 'id' column for later use in the submission\n",
    "test_ids = test_data['id']\n",
    "\n",
    "# Preprocess the test data (excluding 'id')\n",
    "test_data = test_data.drop(['id', 'length'], axis=1)\n",
    "test_data = scaler.transform(test_data)  # Standardize the features\n",
    "\n",
    "# Make predictions using the ANN model\n",
    "test_predictions = model.predict(test_data)\n",
    "# test_predictions2 = model2.predict(test_data)\n",
    "# test_predictions3 = model3.predict(test_data)\n",
    "\n",
    "# Convert the predicted probabilities to labels\n",
    "predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Create a DataFrame with the required format using the 'id' from the test data\n",
    "submission_df = pd.DataFrame({'id': test_ids, 'label': predicted_labels})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('music_genre_predictions_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step\n",
      "Training Accuracy: 0.9423868312757202\n"
     ]
    }
   ],
   "source": [
    "## Calculate Training Accuracy\n",
    "# Load the training data\n",
    "train_data = pd.read_csv('data/train1.csv')\n",
    "\n",
    "# Preprocess the training data\n",
    "labels = train_data['label']\n",
    "train_data = train_data.drop(['filename', 'label', 'length'], axis=1)\n",
    "labels = label_encoder.transform(labels)  # Encode labels\n",
    "\n",
    "# Standardize the features\n",
    "train_data = scaler.transform(train_data)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "train_predictions = model.predict(train_data)\n",
    "train_predictions = np.argmax(train_predictions, axis=1)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "training_accuracy = np.mean(train_predictions == labels)\n",
    "print(f'Training Accuracy: {training_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step\n",
      "[9, 4, 7, 2, 0, 2, 6, 3, 3, 0, 3, 7, 6, 0, 9, 6, 1, 9, 5, 7, 3, 1, 3, 2, 4, 6, 4, 8, 8, 8, 1, 4, 5, 5, 3, 5, 3, 1, 0, 2, 8, 6, 5, 9, 7, 5, 3, 1, 0, 0, 8, 8, 2, 8, 1, 9, 1, 0, 1, 4, 6, 2, 0, 1, 2, 5, 8, 9, 4, 5, 2, 8, 4, 8, 0, 0, 3, 7, 1, 3, 0, 7, 7, 0, 3, 8, 4, 4, 2, 8, 2, 2, 9, 9, 4, 3, 3, 0, 0, 4, 5, 8, 3, 6, 5, 2, 0, 6, 6, 5, 3, 7, 1, 6, 0, 5, 2, 1, 6, 6, 7, 4, 5, 0, 0, 9, 6, 6, 3, 9, 7, 9, 9, 9, 6, 0, 3, 5, 6, 1, 4, 9, 5, 4, 8, 3, 5, 1, 8, 3, 9, 0, 2, 0, 9, 2, 5, 3, 1, 0, 9, 9, 3, 7, 3, 2, 1, 9, 1, 2, 8, 2, 3, 2, 5, 3, 0, 2, 1, 1, 5, 3, 6, 2, 1, 7, 5, 9, 8, 1, 1, 3, 4, 6, 7, 3, 8, 5, 8, 5, 2, 8, 7, 8, 5, 6, 9, 8, 5, 0, 5, 4, 5, 9, 7, 3, 2, 9, 4, 3, 9, 4, 5, 9, 7, 3, 9, 6, 4, 2, 7, 0, 0, 0, 4, 4, 5, 8, 1, 2, 4, 9, 5, 8, 8, 2, 7, 2, 4, 0, 0, 8, 9, 7, 5, 1, 0, 2, 1, 4, 0, 0, 3, 4, 8, 7, 9, 1, 5, 9, 9, 3, 7, 2, 9, 8, 3, 9, 9, 6, 5, 6, 8, 2, 7, 7, 4, 7, 2, 6, 6, 7, 6, 2, 2, 9, 8, 1, 5, 4, 7, 5, 4, 1, 6, 1, 6, 8, 1, 2, 7, 0, 5, 6, 6, 5, 8, 4, 9, 3, 5, 8, 3, 0, 3, 7, 1, 5, 6, 5, 5, 8, 3, 5, 7, 8, 6, 0, 2, 3, 3, 9, 0, 7, 6, 4, 5, 8, 2, 6, 2, 8, 7, 1, 9, 7, 3, 5, 7, 4, 2, 5, 1, 5, 9, 1, 8, 9, 7, 9, 0, 9, 3, 0, 3, 1, 3, 8, 0, 8, 1, 2, 5, 3, 3, 1, 7, 0, 6, 2, 6, 4, 9, 5, 6, 6, 8, 2, 4, 3, 5, 6, 3, 2, 2, 1, 5, 3, 5, 7, 7, 6, 7, 2, 5, 3, 4, 1, 5, 5, 1, 8, 4, 0, 6, 5, 2, 4, 1, 4, 5, 9, 3, 2, 6, 9, 6, 6, 7, 2, 4, 0, 3, 3, 1, 4, 3, 6, 1, 8, 6, 8, 6, 0, 9, 6, 4, 3, 8, 3, 6, 9, 1, 4, 8, 5, 6, 8, 7, 5, 7, 5, 1, 3, 0, 3, 2, 5, 5, 8, 5, 8, 8, 5, 2, 8, 5, 2, 1, 5, 2, 9, 8, 7, 0, 6, 1, 5, 9, 0, 4, 1, 0, 6, 9, 8, 0, 3, 3, 8, 8, 5, 9, 8, 3, 6, 6, 5, 6, 9, 9, 6, 8, 6, 9, 3, 0, 5, 5, 1, 6, 1, 5, 2, 0, 6, 1, 7, 7, 8, 8, 9, 0, 7, 6, 1, 6, 4, 6, 3, 3, 3, 7, 2, 9, 5, 9, 0, 8, 1, 1, 6, 1, 4, 5, 1, 4, 7, 2, 1, 6, 0, 6, 8, 2, 8, 7, 1, 6, 0, 9, 2, 3, 2, 4, 5, 0, 6, 8, 1, 2, 8, 3, 3, 6, 2, 2, 7, 4, 5, 9, 3, 2, 6, 6, 0, 1, 4, 4, 7, 1, 7, 9, 0, 8, 7, 9, 3, 5, 0, 4, 8, 8, 3, 1, 3, 6, 5, 8, 2, 2, 0, 1, 7, 4, 7, 1, 8, 4, 7, 7, 3, 8, 3, 3, 0, 2, 0, 0, 9, 0, 0, 8, 0, 1, 2, 2, 9, 2, 9, 2, 2, 1, 9, 4, 0, 3, 0, 5, 7, 0, 5, 8, 3, 3, 6, 3, 6, 7, 5, 2, 4, 5, 7, 6, 4, 1, 0, 2, 7, 5, 7, 5, 7, 4, 8, 2, 6, 8, 8, 0, 5, 9, 1, 0, 8, 2, 8, 6, 9, 7, 7, 2, 1, 1, 9, 1, 5, 5, 6, 2, 2, 8, 8, 5, 8, 2, 9, 0, 3, 1, 4, 0, 2, 4, 6, 9, 9, 5, 3, 6, 5, 2, 0, 9, 0, 6, 1, 6, 1, 0, 7, 5, 1, 5, 3, 2, 1, 6, 6, 7, 2, 6, 6, 2, 4, 8, 6, 1, 7, 2, 8, 7, 4, 6, 2, 6, 6, 6, 5, 1, 9, 2, 1, 4, 4, 8, 7, 7, 1, 4, 7, 1, 6, 6, 3, 7, 2, 0, 9, 7, 2, 4, 2, 7, 5, 6, 0, 7, 4, 0, 3, 1, 8, 6, 5, 6, 0, 4, 6, 4, 8, 9, 5, 2, 6, 2, 3, 4, 7, 0, 8, 9, 7, 7, 6, 5, 6, 3, 1, 2, 8, 2, 7, 2, 8, 3, 7, 0, 3, 1, 8, 2, 8, 6, 1, 3, 0, 0, 2, 8, 9, 5, 8, 8, 2, 3, 0, 0, 3, 3, 4, 2, 7, 0, 9, 2, 3, 5, 5, 4, 1, 1, 9, 7, 1, 7, 8, 4, 2, 7, 4, 4, 8, 4, 9, 1, 4, 0, 7, 8, 3, 8, 9, 0, 2, 0, 6, 4, 3, 1, 7, 2, 3, 5, 1, 2, 1, 2, 6, 8, 5, 5, 4, 7, 8, 6, 1, 1, 7, 3, 7, 0, 3, 6, 5, 2, 0, 8, 5, 8, 8, 1, 0, 8, 5, 9, 6, 7, 7, 7, 1, 9, 6, 3, 3, 8, 1, 8, 0, 1, 8, 3, 8, 0, 5, 3, 0, 2, 5, 3, 9, 1, 0, 7, 9, 1, 2, 8, 4, 0, 1, 5, 6, 8, 8, 1, 3, 0, 1, 4, 7, 4, 1, 7, 6, 1, 3, 5]\n",
      "0      9\n",
      "1      6\n",
      "2      7\n",
      "3      2\n",
      "4      0\n",
      "      ..\n",
      "994    4\n",
      "995    6\n",
      "996    1\n",
      "997    3\n",
      "998    5\n",
      "Name: label, Length: 999, dtype: int64\n",
      "Accuracy with respect to ground truth: 0.8548548548548549\n"
     ]
    }
   ],
   "source": [
    "## Compare Predictions with Ground Truth\n",
    "import pandas as pd\n",
    "\n",
    "# Load the ground truth labels for comparison\n",
    "ground_truth = pd.read_csv('data/ground_truth.csv')  # Make sure you have a CSV file with the ground truth labels\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('data/test1.csv')\n",
    "\n",
    "# Extract 'id' column for later use in the submission\n",
    "test_ids = test_data['id']\n",
    "\n",
    "# Preprocess the test data (excluding 'id')\n",
    "test_data = test_data.drop(['id', 'length'], axis=1)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# Make predictions using the ANN model\n",
    "test_predictions = model.predict(test_data)\n",
    "\n",
    "# Convert the predicted probabilities to labels\n",
    "predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "print(list(predicted_labels))\n",
    "print(ground_truth['label'])\n",
    "\n",
    "# Compare the predicted labels to the ground truth labels\n",
    "accuracy = (predicted_labels == ground_truth['label']).mean()\n",
    "\n",
    "print(f'Accuracy with respect to ground truth: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
